{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 15:26:46.757844: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-17 15:26:46.887523: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-17 15:26:47.535662: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dnlab/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-04-17 15:26:47.535751: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dnlab/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-04-17 15:26:47.535759: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn; sn.set(font_scale=1.4)\n",
    "from sklearn.utils import shuffle           \n",
    "import matplotlib.pyplot as plt             \n",
    "import cv2                                 \n",
    "import tensorflow as tf                \n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'driving': 0, 'falling_asleep': 1, 'using_cellphone': 2}\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "class_names = ['driving', 'falling_asleep', 'using_cellphone']\n",
    "class_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "nb_classes = len(class_names)\n",
    "\n",
    "IMAGE_SIZE = (150, 150)\n",
    "\n",
    "print(class_names_label)\n",
    "print(nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with Augmented image sets\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def load_data_aug():\n",
    "    datasets = ['/home/dnlab/Data-B/data/main_data/train_cat_new', '/home/dnlab/Data-B/data/main_data/val_cat_new']\n",
    "    output = []\n",
    "\n",
    "    # Define image augmentation\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    for dataset in datasets:\n",
    "        images = []\n",
    "        labels = []\n",
    "\n",
    "        print('Loading {}'.format(dataset))\n",
    "        for folder in os.listdir(dataset):\n",
    "            label = class_names_label[folder]\n",
    "            # iter through each imag in our folder\n",
    "            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n",
    "\n",
    "                # get the path name of the image\n",
    "                img_path = os.path.join(os.path.join(dataset, folder), file)\n",
    "\n",
    "                # Open and resize the img\n",
    "                image = cv2.imread(img_path)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image = cv2.resize(image, IMAGE_SIZE)\n",
    "\n",
    "                # Apply data augmentation\n",
    "                if dataset == '/home/dnlab/Data-B/data/main_data/train_cat_new':\n",
    "                    augmented_image = train_datagen.random_transform(image)\n",
    "                else:\n",
    "                    augmented_image = val_datagen.random_transform(image)\n",
    "\n",
    "                images.append(augmented_image)\n",
    "                labels.append(label)\n",
    "\n",
    "        images = np.array(images, dtype='float32')\n",
    "        labels = np.array(labels, dtype='int32')\n",
    "\n",
    "        output.append((images, labels))\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/dnlab/Data-B/data/main_data/train_cat_new\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2074/2074 [00:09<00:00, 210.41it/s]\n",
      "100%|██████████| 3858/3858 [00:17<00:00, 218.89it/s]\n",
      "100%|██████████| 2664/2664 [00:12<00:00, 211.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/dnlab/Data-B/data/main_data/val_cat_new\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 384/384 [00:00<00:00, 1401.14it/s]\n",
      "100%|██████████| 115/115 [00:00<00:00, 1353.07it/s]\n",
      "100%|██████████| 320/320 [00:00<00:00, 1399.74it/s]\n"
     ]
    }
   ],
   "source": [
    "(train_images2, train_labels2), (test_images2, test_labels2) = load_data_aug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 15:27:32.518466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 80 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:73:00.0, compute capability: 8.6\n",
      "2023-04-17 15:27:43.932360: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.73GiB (rounded to 1856520192)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-04-17 15:27:43.932449: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_0_bfc\n",
      "2023-04-17 15:27:43.932483: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 17, Chunks in use: 17. 4.2KiB allocated for chunks. 4.2KiB in use in bin. 344B client-requested in use in bin.\n",
      "2023-04-17 15:27:43.932504: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 1, Chunks in use: 1. 512B allocated for chunks. 512B in use in bin. 512B client-requested in use in bin.\n",
      "2023-04-17 15:27:43.932524: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2023-04-17 15:27:43.932543: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 3, Chunks in use: 2. 8.5KiB allocated for chunks. 6.5KiB in use in bin. 6.4KiB client-requested in use in bin.\n",
      "2023-04-17 15:27:43.932560: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 1, Chunks in use: 0. 5.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-17 15:27:43.932577: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-17 15:27:43.932592: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-17 15:27:43.932613: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 1, Chunks in use: 1. 36.0KiB allocated for chunks. 36.0KiB in use in bin. 36.0KiB client-requested in use in bin.\n",
      "2023-04-17 15:27:43.932631: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 1, Chunks in use: 0. 65.8KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-17 15:27:43.932648: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-17 15:27:43.932663: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-17 15:27:43.932679: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-17 15:27:43.932694: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-17 15:27:43.932710: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-17 15:27:43.932726: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-17 15:27:43.932742: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-17 15:27:43.932757: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-17 15:27:43.932779: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 2, Chunks in use: 1. 80.32MiB allocated for chunks. 39.82MiB in use in bin. 20.25MiB client-requested in use in bin.\n",
      "2023-04-17 15:27:43.932795: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-17 15:27:43.932811: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-17 15:27:43.932832: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-17 15:27:43.932852: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 1.73GiB was 256.00MiB, Chunk State: \n",
      "2023-04-17 15:27:43.932866: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 84344832\n",
      "2023-04-17 15:27:43.932888: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fcb8e000000 of size 256 next 1\n",
      "2023-04-17 15:27:43.932903: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fcb8e000100 of size 1280 next 2\n",
      "2023-04-17 15:27:43.932917: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fcb8e000600 of size 256 next 3\n",
      "2023-04-17 15:27:43.932931: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fcb8e000700 of size 256 next 4\n",
      "2023-04-17 15:27:43.932945: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fcb8e000800 of size 256 next 6\n",
      "2023-04-17 15:27:43.932958: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fcb8e000900 of size 256 next 7\n",
      "2023-04-17 15:27:43.932972: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fcb8e000a00 of size 256 next 5\n",
      "2023-04-17 15:27:43.932986: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fcb8e000b00 of size 256 next 8\n",
      "2023-04-17 15:27:43.932999: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fcb8e000c00 of size 256 next 13\n",
      "2023-04-17 15:27:43.933013: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fcb8e000d00 of size 256 next 11\n",
      "2023-04-17 15:27:43.933026: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fcb8e000e00 of size 256 next 12\n",
      "2023-04-17 15:27:43.933041: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fcb8e000f00 of size 512 next 18\n",
      "2023-04-17 15:27:43.933056: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fcb8e001100 of size 256 next 16\n",
      "2023-04-17 15:27:43.933070: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fcb8e001200 of size 256 next 17\n",
      "2023-04-17 15:27:43.933084: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fcb8e001300 of size 5120 next 9\n",
      "2023-04-17 15:27:43.933098: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fcb8e002700 of size 3584 next 10\n",
      "2023-04-17 15:27:43.933112: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fcb8e003500 of size 256 next 21\n",
      "2023-04-17 15:27:43.933125: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fcb8e003600 of size 256 next 19\n",
      "2023-04-17 15:27:43.933139: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fcb8e003700 of size 256 next 22\n",
      "2023-04-17 15:27:43.933152: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fcb8e003800 of size 256 next 25\n",
      "2023-04-17 15:27:43.933166: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fcb8e003900 of size 256 next 26\n",
      "2023-04-17 15:27:43.933179: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fcb8e003a00 of size 2048 next 23\n",
      "2023-04-17 15:27:43.933194: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fcb8e004200 of size 3072 next 24\n",
      "2023-04-17 15:27:43.933211: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fcb8e004e00 of size 67328 next 15\n",
      "2023-04-17 15:27:43.933225: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fcb8e015500 of size 36864 next 14\n",
      "2023-04-17 15:27:43.933239: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fcb8e01e500 of size 42467328 next 20\n",
      "2023-04-17 15:27:43.933254: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fcb9089e500 of size 41753344 next 18446744073709551615\n",
      "2023-04-17 15:27:43.933268: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2023-04-17 15:27:43.933286: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 17 Chunks of size 256 totalling 4.2KiB\n",
      "2023-04-17 15:27:43.933303: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 512 totalling 512B\n",
      "2023-04-17 15:27:43.933319: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-04-17 15:27:43.933334: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 3072 totalling 3.0KiB\n",
      "2023-04-17 15:27:43.933348: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 3584 totalling 3.5KiB\n",
      "2023-04-17 15:27:43.933364: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 36864 totalling 36.0KiB\n",
      "2023-04-17 15:27:43.933381: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 41753344 totalling 39.82MiB\n",
      "2023-04-17 15:27:43.933398: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 39.87MiB\n",
      "2023-04-17 15:27:43.933413: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 84344832 memory_limit_: 84344832 available bytes: 0 curr_region_allocation_bytes_: 168689664\n",
      "2023-04-17 15:27:43.933437: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                        84344832\n",
      "InUse:                        41803008\n",
      "MaxInUse:                     84265472\n",
      "NumAllocs:                          43\n",
      "MaxAllocSize:                 41753344\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-04-17 15:27:43.933459: W tensorflow/tsl/framework/bfc_allocator.cc:492] *_________________________________________________**************************xxxxxxxxxxxxxxxxxxxxxxxx\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_59335/2115485300.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(train_images2, train_labels2, batch_size=8, epochs=20, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_accuracy_loss(history):\n",
    "    # Plot loss\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    plt.plot(history.history['loss'],'bo--', label = \"train_loss\")\n",
    "    plt.plot(history.history['val_loss'], 'ro--', label = \"val_loss\")\n",
    "    plt.title(\"train_loss vs val_loss\")\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot accuracy\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    plt.plot(history.history['accuracy'],'bo--', label = \"train_acc\")\n",
    "    plt.plot(history.history['val_accuracy'], 'ro--', label = \"val_acc\")\n",
    "    plt.title(\"train_acc vs val_acc\")\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plot accuracy and loss graphs\n",
    "plot_accuracy_loss(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_examples(class_names, images, true_labels, predicted_labels=None):\n",
    "    \"\"\"\n",
    "    Display 25 images from the images array with their corresponding labels and predicted labels\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    fig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i], cmap=plt.cm.binary)\n",
    "        if predicted_labels is None:\n",
    "            plt.xlabel(class_names[true_labels[i]])\n",
    "        else:\n",
    "            true_label = class_names[true_labels[i]]\n",
    "            predicted_label = class_names[np.argmax(predicted_labels[i])]\n",
    "            if true_label == predicted_label:\n",
    "                color = 'green'\n",
    "            else:\n",
    "                color = 'red'\n",
    "            plt.xlabel(f\"True:{true_label}\\nPred:{predicted_label}\", color=color, fontsize=8)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_images = train_images2 / 255.0 \n",
    "test_images = test_images2 / 255.0\n",
    "\n",
    "\n",
    "# Assuming you have a trained model called \"model\"\n",
    "predicted_labels = model.predict(test_images)\n",
    "\n",
    "# Select 25 random images and their corresponding labels\n",
    "indices = np.random.choice(len(test_images), size=25, replace=False)\n",
    "images_to_plot = test_images[indices]\n",
    "true_labels = test_labels2[indices]\n",
    "predicted_labels = predicted_labels[indices]\n",
    "\n",
    "# Display the selected images with their true and predicted labels\n",
    "display_examples(class_names, images_to_plot, true_labels, predicted_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
